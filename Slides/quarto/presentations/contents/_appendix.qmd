# Appendix {visibility="uncounted"}


## Contact Modeling

* **Objective**: accurately model contacts, impacts and Coulomb friction.
* E.g. Model of bouncing ball

::::{.columns}

:::{.column width=50%}

<br/>

:::{.fragment fragment-index=0}
\begin{align*}
  g_N &= y \\
  \dot{g}_N &= \underbrace{\begin{bmatrix} 0 & 1 \end{bmatrix}}_{W_N} \begin{bmatrix}
  \dot{x} \\ \dot{y}
  \end{bmatrix} =: \gamma_N
\end{align*}
:::

:::{.fragment fragment-index=1}
$$
\gamma_N^+ = -\epsilon_N \gamma_N^-
$$
:::

:::{.fragment fragment-index=2}
* Complementarity Condition
$$
0 \leq \xi_N \perp \lambda_N \geq 0
$$
:::

:::

:::{.column width=50%}
:::{.fragment fragment-index=0}
![](contents/assets/bouncingball.svg){fig-align="center"}
:::

:::{.fragment fragment-index=1}
![](contents/assets/bouncingball_resolved.svg){fig-align="center"}
:::

:::
::::


## Moreau's Time-Stepping {auto-animate="true"}

:::{.fragment fragment-index=0}
* Check if $g_N \leq 0$ at $t + \frac{\Delta t}{2}$
* Solve complementarity
:::

:::{.r-stack}

:::{.fragment .fade-in-then-out fragment-index=0}
\begin{align*}
  \begin{bmatrix}
    m & 0 \\
    0 & m
  \end{bmatrix} &(\dot{q}^+ - \dot{q}^-) - W_N \lambda_N - \begin{bmatrix}
  0 \\ mg
  \end{bmatrix} \Delta t = 0 
\end{align*}
:::

:::{.fragment .fade-in fragment-index=1}
\begin{align*}
  \dot{q}^+ &= \begin{bmatrix}
    m & 0 \\
    0 & m
  \end{bmatrix}^{-1} \left[W_N \lambda_N + \begin{bmatrix}
  0 \\ mg
  \end{bmatrix} \Delta t \right] + \dot{q}^- 
\end{align*}
:::

:::

:::{.r-stack}
:::{.fragment .fade-in-then-out fragment-index=2}
\begin{align*}
  \xi_N = W_N\dot{q}^+ + \epsilon_N W_N \dot{q}^- 
\end{align*}
:::

:::{.fragment .fade-in fragment-index=3}
\begin{align*}
  \xi_N = W_N\begin{bmatrix}
    m & 0 \\
    0 & m
  \end{bmatrix}^{-1} \left[W_N \lambda_N + \begin{bmatrix}
  0 \\ mg
  \end{bmatrix} \Delta t \right] + (1 + \epsilon_N) W_N \dot{q}^-
\end{align*}
:::

:::

:::{.fragment .fade-in fragment-index=4}
Complementarity condition
  \begin{align*}
    \xi_N \lambda_N = 0, \;  
    \xi_N \geq 0, \lambda_N \geq 0
  \end{align*}
:::

:::{.fragment .fade-in fragment-index=4}
* For non-convex optimization, use *Lemke's algorithm*
:::

## Complementarity Formulation

* For potential contacts with gaps $g_N \leq 0$, the following holds.

\begin{align*}
  \begin{gathered}
    0 \leq 
      \xi_N(q, \dot{q}) 
    \perp
        \lambda_N  \geq 0, \\
      \xi_N(q, \dot{q})  :=
        \gamma_N^+ + \epsilon_N \gamma_N^- ,
  \end{gathered}
\end{align*}

:::{.fragment fragment-index=0}
::::{.columns}

:::{.column width=50%}
![](contents/assets/unilateral_primitive.svg){width="500" heigth="500"}
:::

:::{.column width=50%}
![](contents/assets/tangential_to_complementarity.svg)
:::
::::
:::

## Linear Complementarity Problem (LCP)

<br/>

* Objective: pose the complementarity formulation as quadratic function over the contact forces
* Define 
\begin{align*}
  \lambda_R := \mu \lambda_N + \lambda_T, \\
  \lambda_L := \mu \lambda_N - \lambda_T, 
\end{align*}
* Corresponding complementarity is defined
\begin{equation*}
  \begin{gathered}
    0 \leq 
    \begin{pmatrix}
      \xi_R(q, \dot{q}) \\
      \xi_L(q, \dot{q})
    \end{pmatrix} 
    \perp
      \begin{pmatrix}
        \lambda_R  \\
        \lambda_L
      \end{pmatrix} \geq 0,
    \end{gathered}
\end{equation*}

* These definitions help express $\xi_N, \xi_R, \xi_L$ as affine functions of $\lambda_N, \lambda_R, \lambda_L$

\begin{align*}
  \begin{pmatrix}
    \xi_N \\
    \xi_R \\
    \lambda_L
  \end{pmatrix} =
      A
    \begin{pmatrix}
      \lambda_N \\
      \lambda_R \\
      \xi_L
    \end{pmatrix} + b, 
\end{align*}

## LCP

* We substitute the affine functions into the complementarity formulation

:::{.r-stack}
:::{.fragment .fade-in-then-out fragment-index=0}
\begin{equation*}
  \begin{gathered}
    0 \leq 
    \begin{pmatrix}
      \xi_N(q, \dot{q}) \\
      \xi_R(q, \dot{q}) \\
      \xi_L(q, \dot{q})
    \end{pmatrix} 
    \perp
      \begin{pmatrix}
        \lambda_N  \\
        \lambda_R  \\
        \lambda_L
      \end{pmatrix} \geq 0,
    \end{gathered}
\end{equation*}
:::

:::{.fragment .fade-in fragment-index=1}
\begin{align*}
    0 \leq 
    \left[ A \begin{pmatrix}
      \lambda_N \\
      \lambda_R \\
      \xi_L
    \end{pmatrix} + b \right]
    \perp
    \begin{pmatrix}
      \lambda_N \\
      \lambda_R \\
      \xi_L
    \end{pmatrix} \geq 0
\end{align*}
:::
:::

:::{.fragment .fade-in fragment-index=2}
* The LCP can be posed as a feasibility problem and solved for $\lambda_N, \lambda_R, \xi_L$
* In the presence of friction, the LCP is a non-convex optimization problem
* We use pivotting (basis-exchange) technique called Lemke's algorithm to solve the LCP
:::

## Generalization of the log likelihood

* The experts can take many forms. The likelihood can be generalized as

:::{.r-stack}

:::{.fragment .fade-in-then-out fragment-index=0}
$$
  \ln \{P(\mathbb{D} | \theta, \psi) \} = \sum_{j=1}^{N} \ln \sum_{i=1}^{N_F} \mathcal{N} ( \| F_i(x_j; \theta_i) - y_j \| \; | \; 0, s)  P_i(x_j, \psi),
$$
:::

:::{.fragment .fade-in fragment-index=1}
$$
  \ln \{P(\mathbb{D} | \theta, \psi) \} = \sum_{j=1}^{N} \ln \sum_{i=1}^{N_F} \frac{1}{\sqrt{2 \pi s^2}} \exp \left( -\frac{1}{2}\frac{ \|F_i(x_j; \theta_i) - y_j \|^2}{s^2} \right) P_i(x_j, \psi),
$$
:::
:::

:::{.fragment .fade-in fragment-index=2}
* For gradient-based techniques, we can extract the relevant parts and simplify the likelihood
$$
  \ln \{P(\mathbb{D} | \theta, \psi) \} \propto \mathbb{L}(\mathbb{D} | \theta, \psi) = \sum_{j=1}^{N} \sum_{i=1}^{N_F} - \| F_i(x_j; \theta_i) - y_j \|^2 P_i(x_j | \psi). 
$$
:::

:::{.fragment .fade-in fragment-index=3}
:::{.callout-note icon=false}
## Likelihood
$$
\mathbb{L}(\mathbb{D} | \theta, \psi) = \sum_{j=1}^{N} \sum_{i=1}^{N_F} - \| F_i(x_j; \theta_i) - y_j \|^2 P_i(x_j | \psi). 
$$
:::
:::


## Performance Objective

<br/>

::::{.columns}

:::{.column width="60%"}

2. Minimum Trajectory Loss (MTL):

* Accumulated loss may not reflect desired behavior. E.g. Simple pendulum


:::{.fragment fragment-index=0}
* Simple pendulum needs to pump slowly, which would accumulate large cost
:::

:::

:::{.column width="40%"}

:::{.fragment fragment-index=0}
![](contents/assets/mtl.svg){fig-align="right"}
:::

:::
::::


:::{.fragment fragment-index=1}
* MTL encourages trajectories to *eventually* lead to a minimum cost

\begin{align*}
    \begin{gathered}
        t_{min} = \underset{t}{\textrm{inf}} \; \{ \ell(x(t), u): x(t) \in \phi(x_0, u, T) \}  \\
        \mathbb{L}(\phi) = - \frac{\ell(x(t_{min}), u)}{C} \sum_{t=0}^{t_{min}}P_i(x(t) | \psi) 
    \end{gathered} 
\end{align*}
:::


## Stable Switching {auto-animate="true"}

* Given two unstable closed-loop systems

::::{.columns}

:::{.column width=65%}

\begin{align*}
    \dot{x} = A_1x = \begin{bmatrix} 0 & -1 \\ 2 & 0 \end{bmatrix} x, \; \;
    \dot{x} = A_2x = \begin{bmatrix} 0 & -2 \\ 1 & 0 \end{bmatrix} x,
\end{align*}
find stable switching system that converges to $x^*=(0, 0)$

:::{.fragment fragment-index=1}
* Maximum number of state partitions set to 4
:::

:::

:::{.column width=35%}

:::{.fragment fragment-index=0}
![](contents/assets/unstable_switching.png){.absolute top=20 left=700 width="400" height="400"}
:::

:::
::::

:::{.fragment fragment-index=2}
* The gating network $\mathbf{P}(x | \psi)$ is a fully-connected neural net with 4 outputs
* There are 4 experts with parameters $\theta_i$ 
\begin{align*}
    F_i(\theta_i) = \begin{cases}
       0, & \theta_i > \frac{1}{2}, \\
       1, & \theta_i \leq \frac{1}{2},
    \end{cases}
\end{align*}
* **Objective**: learn $(\psi, \theta)$ that minimize the accumulated loss
:::


## Training progress

:::{.r-stack}

:::{.fragment .fade-in-then-out fragment-index=0}
![&nbsp; Control input (purple $\rightarrow \dot{x} = A_1x$, yellow $\rightarrow \dot{x} = A_2 x$) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; State partition ](contents/assets/moeSwitchingIter0.svg){top=100 left=300 }
:::


:::{.fragment .fade-in-then-out fragment-index=1}
![&nbsp; Control input (purple $\rightarrow \dot{x} = A_1x$, yellow $\rightarrow \dot{x} = A_2 x$) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; State partition ](contents/assets/moeSwitchingIter200.svg){ top=50 left=300 }
:::


:::{.fragment .fade-in-then-out fragment-index=2}
![&nbsp; Control input (purple $\rightarrow \dot{x} = A_1x$, yellow $\rightarrow \dot{x} = A_2 x$) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; State partition ](contents/assets/moeSwitchingIter1400.svg){ top=100 left=300 }
:::

:::{.fragment .fade-in fragment-index=3}
![&nbsp; Control input (purple $\rightarrow \dot{x} = A_1x$, yellow $\rightarrow \dot{x} = A_2 x$) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; State partition ](contents/assets/switching_results.svg)
:::

:::


## Passive System Example
<!-- ###################################################################### -->

:::: {.columns}

::: {.column width="30%"}
![](contents/assets/passive-system-example.png)
:::

::: {.column width="70%"}

<br/> 

Kirchoff's law

$$
\begin{aligned}
v &= Ri + \frac{1}{C} \int_{0}^{t} i(\tau) \, \text{d}\tau + L \frac{\text{d} i}{\text{d} t} \\
vi - Ri^2 &= \frac{\text{d}}{\text{d} t} \left( 
  \underbrace{\frac{1}{2C} \left( \int_{0}^{t} i(\tau)\, \text{d} \tau \right)^2}_{\mathcal{V}} + 
  \underbrace{\frac{1}{2} Li^2}_{\mathcal{T}}  
\right)
\end{aligned}
$$
:::

::::

Let $H = \mathcal{V} + \mathcal{T}$, integrate to obtain

$$
\underbrace{H(t)}_{\textrm{available}} -
\underbrace{H(0)}_{\textrm{initial}} 
= 
\underbrace{\int_{0}^{t} v(\tau)i(\tau)\, \text{d} \tau}_{\textrm{supplied}} - 
\underbrace{\int_{0}^{t} Ri^2(\tau)\, \text{d} \tau}_{\textrm{dissipated}}
<
\int_{0}^{t} v(\tau) i(\tau) \, \text{d} \tau
$$


## Uncertainty in Predictions


* The uncertainty associated with each prediction is given by

:::{.callout-note icon="false"}
## Uncertainty in predictions
\begin{align*}
  \Sigma_{F \mid x,\mathbb{D}} = \frac{1}{N_{\theta}-1} \sum_{\theta \sim P(\theta;z)} \| F(x; \theta) - \hat{F}(x)\| ^2.
\end{align*}
where $\hat{F}(x)$ is the marginalized prediction given by
\begin{align*}
  \hat{F}(x) = \frac{1}{N_{\theta}} \sum_{\theta \sim P(\theta;z)} F(x; \theta),
\end{align*} 
:::


## Training Stochastic Models {auto-animate=true}

:::: {.columns}

:::{.column width=60%}

:::{r-vstack}

:::{.r-stack}

:::{.fragment .fade-in-then-out fragment-index=0}
:::{.callout-important icon=false}
## Expectation Maximization

$$
\begin{aligned}
\underset{P(\theta | \mathbb{D})}{\text{maximize}} && P(\mathbb{D} | \theta)  &= \prod_{j=1}^{N} \mathcal{N}(\| F(x_j; \theta) -  y_j \| \; | \; 0, s), \\
\text{subject to} &&
& \theta \sim P(\theta | \mathbb{D}), \\
&& \mathbb{D} &= \{(x_1, y_1), \dots, (x_N, y_N) \}.
\end{aligned}
$$
::: 
<!-- callout -->
::: 
<!-- fragment -->

:::{.fragment .fade-in-then-out fragment-index=1}
:::{.callout-important icon=false}
## Expectation Maximization

$$
\begin{aligned}
\underset{P(\theta| \mathbb{D})}{\text{maximize}} && P(\mathbb{D} | \theta)  &= \prod_{j=1}^{N} \frac{1}{\sqrt{2 \pi s^2}}\exp(-\frac{1}{2s^2}\| F(x_j; \theta) -  y_j \|^2), \\
\text{subject to} &&
& \theta \sim P(\theta| \mathbb{D}), \\
&& \mathbb{D} &= \{(x_1, y_1), \dots, (x_N, y_N) \}.
\end{aligned}
$$
::: 
<!-- callout -->
::: 
<!-- fragment -->

:::{.fragment .fade-in fragment-index=2}
:::{.callout-important icon=false}
## Expectation Maximization

$$
\begin{aligned}
\underset{z}{\text{maximize}} && P(\mathbb{D} | \theta)  &= \prod_{j=1}^{N} \frac{1}{\sqrt{2 \pi s^2}}\exp(-\frac{1}{2s^2}\| F(x_j; \theta) -  y_j \|^2), \\
\text{subject to} &&
& \theta \sim Q(\theta;z), \\
&& \mathbb{D} &= \{(x_1, y_1), \dots, (x_N, y_N) \}.
\end{aligned}
$$
::: 
<!-- callout -->
::: 
<!-- fragment -->
::: 
<!-- r-stack -->


::: 
<!-- r-vstack -->
::: 
<!-- column -->

:::{.column width=40%}

![](contents/assets/handwritten_images.png){.absolute top=50 left=750 width="350" height="200"}


::: 
<!-- column -->
:::: 

:::: {.columns}

:::{.column width=60%}
:::{.fragment .fade-in fragment-index=3}
![](contents/assets/overfitting.svg){.absolute top=150 left=0 width="650" height="650"}
::: 
<!-- fragment -->
:::

:::{.column width=40%}

:::{.fragment .fade-in fragment-index=3}
:::{.incremental}
* Expectation maximization is prone to overfitting
    + Reduces accuracy of predictions
    + Reports near-zero prediction uncertainty (*overconfident*)
* **Solution**: enforce variance on the posterior 
::: 
<!--incremental -->

::: 
<!-- fragment -->
:::

::::

## Bias-Variance Trade-Off {auto-animate=true}


<br/>

* Prior distribution plays the role of a *regularization term*

:::{.fragment .fade-in fragment-index=0}
:::{.callout-important icon=false}
## Bayesian Inference

$$
\begin{aligned}
\underset{z}{\text{maximize}} &&& P(\mathbb{D} | \theta) P(\theta), \\
\text{subject to} &&
& \theta \sim Q(\theta;z), \\
&& \mathbb{D} &= \{(x_1, y_1), \dots, (x_N, y_N) \}.
\end{aligned}
$$
::: 
<!-- callout -->
:::
<!-- fragment -->

:::{.fragment fragment-index=1}

* Prior distribution can be
    + *Informed*: allows us to inject prior knowledge
    + *Uninformed*: starts randomly but every so often gets updated by the posterior

:::


## Bias-Variance Trade-Off {auto-animate=true}


<br/>

* Prior distribution plays the role of a *regularization term*

:::{.r-stack}

:::{.fragment .fade-in-then-out fragment-index=0}
:::{.callout-important icon=false}
## Bayesian Inference

$$
\begin{aligned}
\underset{P(\theta | \mathbb{D})}{\text{maximize}} &&& P(\mathbb{D} | \theta) P(\theta), \\
\text{subject to} &&
& \theta \sim P(\theta | \mathbb{D}), \\
&& \mathbb{D} &= \{(x_1, y_1), \dots, (x_N, y_N) \}.
\end{aligned}
$$
::: 
<!-- callout -->

:::
<!-- fragment -->

:::{.fragment .fade-in-then-out fragment-index=1}
:::{.callout-warning icon="false"}
## Regularization via Prior Distribution
$$
P(\mathbb{D} | \theta) P(\theta) =  \prod_{j=1}^{N} \mathcal{N}(\| F(x_j; \theta) -  y_j \| \; | \; 0, s_1) \mathcal{N}(\| \theta - \theta_0 \| \; | \; 0, s_2)
$$ 
$$
P(\mathbb{D} | \theta) P(\theta) =  \prod_{j=1}^{N} \frac{1}{2 \pi s_1s_2}\exp(-\frac{1}{2s_1^2}\| F(x_j; \theta) -  y_j \|^2)\exp(-\frac{1}{2s_2^2}\| \theta - \theta_0 \|^2)
$$ 
$$
\ln P(\mathbb{D} | \theta) P(\theta) = \ln{\frac{N}{2 \pi s_1s_2}} + \sum_{j=1}^{N} -\frac{1}{2s_1^2}\| F(x_j; \theta) -  y_j \|^2 - \frac{1}{2s_2^2}\| \theta - \theta_0 \|^2
$$
:::
<!-- callout -->

:::
<!-- fragment -->

:::{.fragment .fade-in fragment-index=2}
:::{.callout-important icon=false}
## Bayesian Inference

$$
\begin{aligned}
\underset{P(\theta | \mathbb{D})}{\text{maximize}} &&& P(\mathbb{D} | \theta) P(\theta), \\
\text{subject to} &&
& \theta \sim P(\theta | \mathbb{D}), \\
&& \mathbb{D} &= \{(x_1, y_1), \dots, (x_N, y_N) \}.
\end{aligned}
$$
::: 
<!-- callout -->

:::
<!-- fragment -->
:::
<!-- r-stack-->

:::{.fragment fragment-index=3}

* Prior distribution can be
    + *Informed*: allows us to inject prior knowledge
    + *Uninformed*: starts randomly but every so often gets updated by the posterior

:::

## Estimating Posterior Distribution {auto-animate=true}

<br/>

:::{.callout-important icon=false}
## Bayesian Inference

$$
\begin{aligned}
\underset{z}{\text{maximize}} &&& P(\mathbb{D} | \theta) P(\theta), \\
\text{subject to} &&
& \theta \sim Q(\theta;z), \\
&& \mathbb{D} &= \{(x_1, y_1), \dots, (x_N, y_N) \}.
\end{aligned}
$$
::: 
<!-- callout -->

* **Variational Inference**: approximates the posterior $P(\theta | \mathbb{D})$ with a pre-selected distribution $Q(\theta; z)$
* **Objective**: collect $N_\theta$ samples from the current posterior $Q(\theta; z)$ and maximize <span style="font-variant:small-caps;">Elbo</span> 
$$
  \mathcal{L}(\mathbb{D},z) = \mathbb{E}_{\theta \sim Q} \left[\ln(P(\mathbb{D} \mid \theta;z)P(\theta)) - \ln(Q(\theta;z)) \right].
$$

## Bias-Variance Tradeoff

::: {.callout-important icon=false}
## Bias-Variance Tradeoff
$$
\begin{aligned}
h(x) &= \sin(x) \\
\mathcal{D} &= {h(x)+\epsilon_i, \epsilon_i \sim \mathcal{N}(0, \delta)} \\
y &= y(x; \mathcal{D}) \\
\mathbb{E}_{\mathcal{D}}[(y-h)^2] &= {\underbrace{(\mathbb{E}_{\mathcal{D}}[y-h])^2}_{\text{bias}^2}} + {\underbrace{\mathbb{E}_{\mathcal{D}}[y - \mathbb{E}_{\mathcal{D}}(y)^2]}_{\text{variance}}}
\end{aligned}
$$
:::
*Finding deterministic solution under noise has low bias and high variance (overfits)

## Bayesian Learning {.smaller}
<!-- ###################################################################### -->


$$
p(\theta \mid \mathcal{D}) = \frac{\overbrace{p(\mathcal{D} \mid
\theta)}^{\text{likelihood}}\overbrace{p(\theta)}^{\text{prior}}}
{\underbrace{\int_\theta p(\mathcal{D} \mid \theta^\prime)p(\theta^\prime)
d\theta^\prime}_{\text{evidence}}} \underbrace{\approx q(\theta;
z)}_{\text{VI}}.
$$

:::: {.fragment .semi-fade-out fragment-index=1}
::: {layout="[1,1]" layout-valign="center"}
![Show ELBO convergence.](contents/assets/pbc-outline.svg){width=200%}

::: {.callout-important icon=false}
## KL-divergence and ELBO
$$
\begin{aligned}
D_{\text{KL}} &= \mathbb{E}_{\theta \sim q}\left[ \log \frac{q(\theta;
z)}{p(\theta \mid \mathcal{D})}\right] \\
&= \log p(\mathcal{D}) - \mathbb{E}_{\theta \sim q}\left[ \log
\frac{p(\mathcal{D} \mid \theta) p(\theta)}{q(\theta; z)} \right] \\
\mathcal{L}(\mathcal{D}; z) &= \mathbb{E}_{\theta \sim q}\left[ \log
p(\mathcal{D} \mid \theta) p(\theta) - \log q(\theta; z) \right]
\end{aligned}
$$
:::

:::
::::

:::: {.fragment fragment-index=1}
::: {layout="[1,1]" layout-valign="center"}
![Show prob. distribution](contents/assets/pbc-outline.svg){width=100%}

::: {.callout-tip icon=false}
## Prediction through marginalization
$$
\begin{aligned}
\hat{m} &= \frac{1}{N}\sum_{\theta \sim q} m(x, \theta).
\end{aligned}
$$
:::

:::
::::

## <span style="font-variant:small-caps;">NeuralIdaPbc</span> Main Problem {.smaller visibility="uncounted"}
<!-- ###################################################################### -->

$$\begin{aligned} \underset{\theta}{\text{minimize}} && J(\theta) &= \left\lVert G^{\bot} \left\{ \nabla_{q} H - M_{d}^{\theta}M^{-1} \nabla_{q} H_{d}^{\theta} + J_{2}^{\theta} \left(M_{d}^{\theta}\right)^{-1} p \right\} \right\rVert^2  \\ \text{subject to}  && H_d^{\theta} &= \frac{1}{2} p^{\top} \left( M_{d}^{\theta} \right)^{-1} p + V_{d}^{\theta}(q) \\ && M_d^{\theta}(q) &= \left(M_d^{\theta}(q)\right)^\top \succ 0 \\ && J_{2}^{\theta}(q,p) &= -\left(J_{2}^{\theta}(q,p)\right)^\top \\ && q^\star &= \underset{q}{\arg \min} \, V_{d}^{\theta} (q) \end{aligned}$$

::::: {.fragment}
:::: {.columns}

::: {.column width=49%}

::: {.callout-tip icon="false"}
## <span style="font-variant:small-caps;">NeuralIdaPbc</span>

- Solve nonlinear PDEs using neural networks and SoS polynomials
- Surrogates of $M_d$, $J_2$, $V_d$ are constrained *by construction*

:::

:::

::: {.column width=2%} 

:::

::: {.column width=49%}
::: {.callout-tip icon="false"}
## <span style="font-variant:small-caps;">Pinn</span>

- Solve nonlinear PDEs using neural networks
- Solution surrogates are constrained via penalty term in loss function


:::
:::

::::
:::::

